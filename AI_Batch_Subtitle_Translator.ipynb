{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP0eAK3GDdKu28HeYPogF4/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jack978397/Colab-AI-Transcribe-Translate/blob/main/AI_Batch_Subtitle_Translator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TRvUzqGceul3",
        "outputId": "efc6856c-e99a-47e7-8849-b0fb0edcd663"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m24.2/24.2 MB\u001b[0m \u001b[31m70.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.0/56.0 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hâœ… ç’°å¢ƒæº–å‚™å®Œæˆï¼\n"
          ]
        }
      ],
      "source": [
        "!pip install -q -U google-generativeai gradio\n",
        "print(\"âœ… ç’°å¢ƒæº–å‚™å®Œæˆï¼\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import google.generativeai as genai\n",
        "import os\n",
        "import time\n",
        "\n",
        "# --- 1. æ ¸å¿ƒç¿»è­¯å¼•æ“ ---\n",
        "class StandaloneTranslator:\n",
        "    def __init__(self, api_key):\n",
        "        genai.configure(api_key=api_key)\n",
        "        self.model = genai.GenerativeModel('gemini-3.1-pro-preview')\n",
        "\n",
        "    def translate(self, text, src_lang, dst_lang):\n",
        "        prompt = f\"ä½ æ˜¯ä¸€ä½è³‡æ·±çš„{dst_lang}æ•™å­¸è€å¸«ã€‚è«‹å°‡ä»¥ä¸‹ SRT å­—å¹•ç²¾æº–ç¿»è­¯ç‚ºæµæš¢ã€å£èªçš„{dst_lang}ã€‚è¦å‰‡ï¼š1.ç¶­æŒæ™‚é–“è»¸ 2.ä¿ç•™å¼•è™Ÿ 3.å¥å°¾ä¸åŠ æ¨™é» 4.å°‡ ã€‡ã€‡ æ›æˆ ï½ã€‚\\n\\nå…§å®¹ï¼š\\n{text}\"\n",
        "        response = self.model.generate_content(prompt, generation_config=genai.types.GenerationConfig(temperature=0.1))\n",
        "        return response.text\n",
        "\n",
        "# --- 2. è™•ç†é‚è¼¯ (æ”¯æŒå¯¦æ™‚æ›´æ–°) ---\n",
        "def batch_translate_handler(api_key, files, src_lang, dst_lang, progress=gr.Progress()):\n",
        "    if not api_key:\n",
        "        yield \"âŒ è«‹å¡«å…¥ API Key\", []\n",
        "        return\n",
        "    if not files:\n",
        "        yield \"âŒ è«‹å…ˆä¸Šå‚³æª”æ¡ˆ\", []\n",
        "        return\n",
        "\n",
        "    translator = StandaloneTranslator(api_key)\n",
        "    log_content = \"ğŸš€ å•Ÿå‹•å…¨è‡ªå‹•æ‰¹æ¬¡è™•ç†...\\n\"\n",
        "    output_files = []\n",
        "\n",
        "    for i, file_obj in enumerate(files):\n",
        "        filename = os.path.basename(file_obj.name)\n",
        "        log_content += f\"æ­£åœ¨ç¿»è­¯ ({i+1}/{len(files)}): {filename}...\\n\"\n",
        "\n",
        "        # å¯¦æ™‚æ›´æ–°ï¼šè®“ç•«é¢ä¸Šå‡ºç¾ã€Œæ­£åœ¨ç¿»è­¯ã€çš„è¨Šæ¯\n",
        "        yield log_content, output_files\n",
        "\n",
        "        try:\n",
        "            with open(file_obj.name, \"r\", encoding=\"utf-8\") as f:\n",
        "                content = f.read()\n",
        "\n",
        "            # å‘¼å« Gemini (é€™æ®µæœƒèŠ±æ¯”è¼ƒå¤šæ™‚é–“ï¼Œè«‹è§€å¯Ÿ Colab å¾Œå°ä¹Ÿæœ‰è¼¸å‡º)\n",
        "            print(f\"--- æ­£åœ¨ç™¼é€è‡³ Gemini 3.1: {filename} ---\")\n",
        "            translated = translator.translate(content, src_lang, dst_lang)\n",
        "\n",
        "            out_name = f\"translated_{dst_lang}_{filename}\"\n",
        "            with open(out_name, \"w\", encoding=\"utf-8\") as f:\n",
        "                f.write(translated)\n",
        "\n",
        "            output_files.append(out_name)\n",
        "            log_content += f\"âœ… {filename} è™•ç†å®Œç•¢ï¼\\n\\n\"\n",
        "\n",
        "            # å¯¦æ™‚æ›´æ–°ï¼šæ¯ç¿»å®Œä¸€å€‹æª”æ¡ˆå°±æ›´æ–°ä¸€æ¬¡ç•«é¢\n",
        "            yield log_content, output_files\n",
        "\n",
        "        except Exception as e:\n",
        "            log_content += f\"âŒ {filename} ç™¼ç”ŸéŒ¯èª¤: {str(e)}\\n\"\n",
        "            yield log_content, output_files\n",
        "\n",
        "    log_content += \"--- ğŸ‰ å…¨éƒ¨ä»»å‹™åŸ·è¡Œå®Œç•¢ ---\"\n",
        "    yield log_content, output_files\n",
        "\n",
        "# --- 3. å°ˆå±¬ UI ---\n",
        "with gr.Blocks(title=\"AI å­—å¹•ç¿»è­¯å¸«\") as translator_app:\n",
        "    gr.Markdown(\"# ğŸŒ AI å°ˆæ¥­å­—å¹•ç¨ç«‹ç¿»è­¯ç³»çµ± (å¯¦æ™‚æ—¥èªŒç‰ˆ)\")\n",
        "    api_key_input = gr.Textbox(label=\"ğŸ”‘ Gemini API Key\", type=\"password\")\n",
        "\n",
        "    with gr.Row():\n",
        "        with gr.Column():\n",
        "            file_input = gr.File(label=\"ä¸Šå‚³ SRT å­—å¹•æª” (æ”¯æ´å¤šé¸)\", file_count=\"multiple\", file_types=[\".srt\"])\n",
        "            src_lang = gr.Dropdown([\"æ—¥æ–‡\", \"è‹±æ–‡\", \"ç¹é«”ä¸­æ–‡\"], label=\"ä¾†æºèªç³»\", value=\"æ—¥æ–‡\")\n",
        "            dst_lang = gr.Dropdown([\"ç¹é«”ä¸­æ–‡\", \"è‹±æ–‡\", \"æ—¥æ–‡\"], label=\"ç›®æ¨™èªç³»\", value=\"ç¹é«”ä¸­æ–‡\")\n",
        "            btn = gr.Button(\"ğŸš€ å•Ÿå‹•å…¨è‡ªå‹•æ‰¹æ¬¡ç¿»è­¯\", variant=\"primary\")\n",
        "        with gr.Column():\n",
        "            out_preview = gr.Textbox(label=\"å¯¦æ™‚è™•ç†æ—¥èªŒ (æ¯å®Œæˆä¸€å€‹æª”æ¡ˆæœƒæ›´æ–°ä¸€æ¬¡)\", lines=12, interactive=False)\n",
        "            out_files = gr.File(label=\"ğŸ“¥ ä¸‹è¼‰ç¿»è­¯å¾Œçš„å…¨éƒ¨æª”æ¡ˆ\")\n",
        "\n",
        "    # æ³¨æ„é€™è£¡çš„è¼¸å‡ºç¶å®š\n",
        "    btn.click(batch_translate_handler, [api_key_input, file_input, src_lang, dst_lang], [out_preview, out_files])\n",
        "\n",
        "translator_app.queue().launch(debug=True, share=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 651
        },
        "id": "kf80_9NOfEkk",
        "outputId": "0e87fe40-4cb1-4421-835d-4c4b9e3a91bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://5fd77a7198848c22dd.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://5fd77a7198848c22dd.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- æ­£åœ¨ç™¼é€è‡³ Gemini 3.1: EP14-1_whisperæ—¥å­—.srt ---\n",
            "--- æ­£åœ¨ç™¼é€è‡³ Gemini 3.1: EP14-2_whisperæ—¥å­—.srt ---\n",
            "--- æ­£åœ¨ç™¼é€è‡³ Gemini 3.1: EP14-3_whisperæ—¥å­—.srt ---\n"
          ]
        }
      ]
    }
  ]
}