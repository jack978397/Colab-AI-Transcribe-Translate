{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMs5p7M/Ee7w5WmCaYl5V+a",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jack978397/Colab-AI-Transcribe-Translate/blob/main/1_Whisper_Transcription_Hub.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pMypEvui4pET"
      },
      "outputs": [],
      "source": [
        "# --- 1. ä¿®æ­£å®‰è£æŒ‡ä»¤ (åŠ å…¥ Google AI åº«) ---\n",
        "!pip install openai-whisper yt-dlp srt \"moviepy<2.0.0\" Gradio google-generativeai\n",
        "!apt-get install -y ffmpeg\n",
        "\n",
        "print(\"\\n--- API ç’°å¢ƒå®‰è£å®Œæˆï¼ ---\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import whisper\n",
        "import torch\n",
        "import os\n",
        "import re\n",
        "import datetime\n",
        "import srt\n",
        "import yt_dlp\n",
        "\n",
        "# --- 2. å­—å¹•è™•ç†å·¥å…· ---\n",
        "def format_srt_time(seconds):\n",
        "    if seconds < 0: seconds = 0\n",
        "    delta = datetime.timedelta(seconds=seconds)\n",
        "    hours, remainder = divmod(delta.seconds, 3600)\n",
        "    minutes, seconds = divmod(remainder, 60)\n",
        "    milliseconds = delta.microseconds // 1000\n",
        "    return f\"{hours:02}:{minutes:02}:{seconds:02},{milliseconds:03}\"\n",
        "\n",
        "def refine_srt_segments(segments, max_chars=18):\n",
        "    if not segments: return []\n",
        "    pre_filtered = []\n",
        "    last_text = None\n",
        "    for seg in segments:\n",
        "        text = seg['text'].strip()\n",
        "        if not text: continue\n",
        "        if text == last_text and (seg['end'] - seg['start']) < 0.8:\n",
        "            if pre_filtered: pre_filtered[-1]['end'] = seg['end']\n",
        "            continue\n",
        "        pre_filtered.append(seg)\n",
        "        last_text = text\n",
        "\n",
        "    final_segments = []\n",
        "    punctuation_pattern = r'([ï¼Œã€‚ã€ï¼Ÿï¼,.\\!\\?])'\n",
        "    for segment in pre_filtered:\n",
        "        text = segment['text'].strip()\n",
        "        if len(text) <= max_chars:\n",
        "            final_segments.append(segment)\n",
        "            continue\n",
        "        start_time, end_time = segment['start'], segment['end']\n",
        "        duration = end_time - start_time\n",
        "        parts = re.split(punctuation_pattern, text)\n",
        "        sub_sentences = [p for p in parts if p.strip()]\n",
        "\n",
        "        current_sentence = \"\"\n",
        "        total_len = sum(len(s) for s in sub_sentences)\n",
        "        current_start = start_time\n",
        "        for sub in sub_sentences:\n",
        "            if len(current_sentence) > 0 and len(current_sentence + sub) > max_chars:\n",
        "                ratio = len(current_sentence) / total_len\n",
        "                new_end = current_start + (ratio * duration)\n",
        "                final_segments.append({'start': current_start, 'end': new_end, 'text': current_sentence})\n",
        "                current_start = new_end\n",
        "                current_sentence = sub\n",
        "            else:\n",
        "                current_sentence += (\" \" if current_sentence and not re.match(r'^[ï¼Œã€‚ã€ï¼Ÿï¼]', sub) else \"\") + sub\n",
        "        if current_sentence:\n",
        "            final_segments.append({'start': current_start, 'end': end_time, 'text': current_sentence})\n",
        "\n",
        "    deduped = []\n",
        "    for s in final_segments:\n",
        "        if not deduped or s['text'] != deduped[-1]['text']:\n",
        "            deduped.append(s)\n",
        "        else:\n",
        "            deduped[-1]['end'] = s['end']\n",
        "    for i, seg in enumerate(deduped): seg['id'] = i\n",
        "    return deduped\n",
        "\n",
        "def generate_srt_from_segments(segments):\n",
        "    srt_content = []\n",
        "    for i, segment in enumerate(segments):\n",
        "        start_time, end_time = format_srt_time(segment['start']), format_srt_time(segment['end'])\n",
        "        text = segment['text'].strip()\n",
        "        if text:\n",
        "            srt_content.append(str(i + 1))\n",
        "            srt_content.append(f\"{start_time} --> {end_time}\")\n",
        "            srt_content.append(text)\n",
        "            srt_content.append(\"\")\n",
        "    return \"\\n\".join(srt_content)\n",
        "\n",
        "def fix_and_process_srt(srt_content, remove_punctuation=True):\n",
        "    try:\n",
        "        cleaned_content = \"\\n\".join(line for line in srt_content.strip().splitlines() if line.strip())\n",
        "        subs = list(srt.parse(cleaned_content))\n",
        "        punctuations_to_remove = '.,ã€‚?!ï¼?ï¼Ÿ'\n",
        "        for sub in subs:\n",
        "            mod = sub.content.strip()\n",
        "            if remove_punctuation: mod = mod.rstrip(punctuations_to_remove)\n",
        "            sub.content = mod.strip()\n",
        "        return srt.compose(subs)\n",
        "    except: return srt_content\n",
        "\n",
        "# --- 4. è½‰éŒ„è¾¨è­˜å¼•æ“ ---\n",
        "class WhisperEngineCloud:\n",
        "    def __init__(self):\n",
        "        self.model = None\n",
        "        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "        self.model_size = None\n",
        "\n",
        "    def load_model(self, model_size=\"large\"):\n",
        "        if self.model is not None and self.model_size == model_size: return\n",
        "        print(f\"æ­£åœ¨è¼‰å…¥æ¨¡å‹ {model_size}...\")\n",
        "        self.model = whisper.load_model(model_size, device=self.device)\n",
        "        self.model_size = model_size\n",
        "        print(\"è¼‰å…¥æˆåŠŸã€‚\")\n",
        "\n",
        "    def transcribe(self, audio_path, prompt=\"\"):\n",
        "        return self.model.transcribe(\n",
        "            audio_path,\n",
        "            initial_prompt=prompt,\n",
        "            verbose=True,\n",
        "            compression_ratio_threshold=2.4,\n",
        "            no_speech_threshold=0.6\n",
        "        )\n",
        "\n",
        "engine = WhisperEngineCloud()\n",
        "print(\"\\n--- è½‰éŒ„å¼•æ“ (ç²¾ç°¡å·¥ä½œç«™ç‰ˆ) è¼‰å…¥å®Œç•¢ï¼ ---\")\n"
      ],
      "metadata": {
        "id": "hKnBIT1i6LES"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import gc\n",
        "import torch\n",
        "import os\n",
        "\n",
        "def process_transcription(file_input, yt_input, input_type, model_size, prompt, remove_punc, progress=gr.Progress()):\n",
        "    gc.collect()\n",
        "    torch.cuda.empty_cache()\n",
        "    progress(0, desc=\"ğŸš€ æ­£åœ¨æº–å‚™å¼•æ“...\")\n",
        "\n",
        "    if input_type == \"æª”æ¡ˆä¸Šå‚³\":\n",
        "        if not file_input: return \"âŒ éŒ¯èª¤ï¼šè«‹å…ˆä¸Šå‚³æª”æ¡ˆã€‚\", None\n",
        "        audio_source, output_video = file_input, None\n",
        "    else:\n",
        "        if not yt_input: return \"âŒ éŒ¯èª¤ï¼šè«‹è¼¸å…¥ YouTube ç¶²å€\", None\n",
        "        progress(0.1, desc=\"æ­£åœ¨å¾ YouTube é›²ç«¯æŠ“å–...\")\n",
        "        ydl_opts = {'format': 'bestvideo[ext=mp4]+bestaudio[ext=m4a]/best[ext=mp4]/best', 'outtmpl': 'downloaded_video.%(ext)s', 'noplaylist': True}\n",
        "        with yt_dlp.YoutubeDL(ydl_opts) as ydl: ydl.download([yt_input])\n",
        "        audio_source, output_video = 'downloaded_video.mp4', 'downloaded_video.mp4'\n",
        "\n",
        "    engine.load_model(model_size)\n",
        "    progress(0.4, desc=f\"ğŸ”¥ æ­£åœ¨è¾¨è­˜ ({model_size} æ¨¡å‹)...\")\n",
        "    result = engine.transcribe(audio_source, prompt)\n",
        "\n",
        "    progress(0.8, desc=\"æ ¼å¼ä½ˆç½®ä¸­...\")\n",
        "    refined = refine_srt_segments(result['segments'])\n",
        "    srt_content = generate_srt_from_segments(refined)\n",
        "    final_srt = fix_and_process_srt(srt_content, remove_punctuation=remove_punc)\n",
        "\n",
        "    srt_output_path = os.path.abspath(\"original_transcript.srt\")\n",
        "    with open(srt_output_path, \"w\", encoding=\"utf-8\") as f: f.write(final_srt)\n",
        "\n",
        "    out_files = [srt_output_path]\n",
        "    if output_video: out_files.append(os.path.abspath(output_video))\n",
        "    return final_srt, out_files\n",
        "\n",
        "# --- å–®ç´”è½‰éŒ„ UI ---\n",
        "with gr.Blocks(title=\"Whisper Pro è½‰éŒ„å·¥ä½œç«™\") as demo:\n",
        "    gr.Markdown(\"# ğŸš€ Whisper Pro å½±éŸ³è½‰éŒ„èˆ‡æ ¡ç¨¿å·¥ä½œç«™\")\n",
        "\n",
        "    with gr.Row():\n",
        "        with gr.Column(scale=1):\n",
        "            t_mode = gr.Radio([\"æª”æ¡ˆä¸Šå‚³\", \"YouTube é€£çµ\"], label=\"è¼¸å…¥æ¨¡å¼\", value=\"æª”æ¡ˆä¸Šå‚³\")\n",
        "            t_file = gr.File(label=\"ä¸Šå‚³\")\n",
        "            t_url = gr.Textbox(label=\"ç¶²å€\", visible=False)\n",
        "            t_model = gr.Dropdown([\"base\", \"medium\", \"large\"], label=\"ä½¿ç”¨æ¨¡å‹ (å»ºè­°ç”¨ large)\", value=\"large\")\n",
        "            t_btn = gr.Button(\"ğŸ”¥ é–‹å§‹è½‰éŒ„è¾¨è­˜\", variant=\"primary\")\n",
        "\n",
        "        with gr.Column(scale=2):\n",
        "            gr.Markdown(\"### âœï¸ åŸéŸ³å­—å¹•é è¦½ (æ ¡ç¨¿å€)\")\n",
        "            with gr.Row():\n",
        "                f_in = gr.Textbox(placeholder=\"å°‹æ‰¾\", label=\"å°‹æ‰¾\", scale=2)\n",
        "                r_in = gr.Textbox(placeholder=\"å–ä»£\", label=\"å–ä»£\", scale=2)\n",
        "                rep_btn = gr.Button(\"å…¨éƒ¨å–ä»£\", scale=1)\n",
        "            t_preview = gr.Textbox(label=\"å­—å¹•å…§å®¹ï¼ˆå¯åœ¨é€™è£¡ç›´æ¥æ‰‹å‹•ä¿®æ”¹ï¼‰\", lines=18, interactive=True)\n",
        "            t_out = gr.File(label=\"ğŸ“¥ ä¸‹è¼‰ SRT å­—å¹• (å³éµå¦å­˜å¯å­˜åˆ°æŒ‡å®šå¤¾)\", file_count=\"multiple\")\n",
        "\n",
        "    def t_toggle(choice):\n",
        "        if choice == \"YouTube é€£çµ\": return gr.update(visible=False), gr.update(visible=True)\n",
        "        return gr.update(visible=True), gr.update(visible=False)\n",
        "    t_mode.change(t_toggle, t_mode, [t_file, t_url])\n",
        "\n",
        "    def do_replace(text, f, r):\n",
        "        new_text = text.replace(f, r) if f else text\n",
        "        path = os.path.abspath(\"original_transcript.srt\")\n",
        "        with open(path, \"w\", encoding=\"utf-8\") as file: file.write(new_text)\n",
        "        return new_text, [path]\n",
        "\n",
        "    rep_btn.click(do_replace, [t_preview, f_in, r_in], [t_preview, t_out])\n",
        "    t_btn.click(process_transcription, [t_file, t_url, t_mode, t_model, gr.State(\"\"), gr.State(True)], [t_preview, t_out])\n",
        "\n",
        "demo.queue().launch(debug=True, share=True)\n"
      ],
      "metadata": {
        "id": "LxzQ9Qiv71V2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}