{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyN+FddqnwroRasCM/s2CW+L",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jack978397/Colab-AI-Transcribe-Translate/blob/main/1_Whisper_Transcription_Hub.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pMypEvui4pET"
      },
      "outputs": [],
      "source": [
        "# --- 1. ä¿®æ­£å®‰è£æŒ‡ä»¤ (åŠ å…¥ Google AI åº«) ---\n",
        "!pip install openai-whisper yt-dlp srt \"moviepy<2.0.0\" Gradio google-generativeai\n",
        "!apt-get install -y ffmpeg\n",
        "\n",
        "print(\"\\n--- API ç’°å¢ƒå®‰è£å®Œæˆï¼ ---\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import whisper\n",
        "import torch\n",
        "import os\n",
        "import re\n",
        "import datetime\n",
        "import srt\n",
        "import yt_dlp\n",
        "import gc\n",
        "\n",
        "# --- 1. æ ¸å¿ƒå·¥å…·å‡½å¼ ---\n",
        "def format_srt_time(seconds):\n",
        "    delta = datetime.timedelta(seconds=max(0, seconds))\n",
        "    hours, remainder = divmod(delta.seconds, 3600)\n",
        "    minutes, seconds = divmod(remainder, 60)\n",
        "    milliseconds = delta.microseconds // 1000\n",
        "    return f\"{hours:02}:{minutes:02}:{seconds:02},{milliseconds:03}\"\n",
        "\n",
        "def refine_srt_segments(segments, max_chars=18):\n",
        "    if not segments: return []\n",
        "    pre_filtered = []\n",
        "    last_text = None\n",
        "    for seg in segments:\n",
        "        text = seg['text'].strip()\n",
        "        if not text: continue\n",
        "        if text == last_text and (seg['end'] - seg['start']) < 0.8:\n",
        "            if pre_filtered: pre_filtered[-1]['end'] = seg['end']\n",
        "            continue\n",
        "        pre_filtered.append(seg)\n",
        "        last_text = text\n",
        "\n",
        "    final_segments = []\n",
        "    punctuation_pattern = r'([ï¼Œã€‚ã€ï¼Ÿï¼,.\\!\\?])'\n",
        "    for segment in pre_filtered:\n",
        "        text = segment['text'].strip()\n",
        "        if not text or len(text) <= max_chars:\n",
        "            final_segments.append(segment)\n",
        "            continue\n",
        "        start_time, end_time = segment['start'], segment['end']\n",
        "        duration = end_time - start_time\n",
        "        parts = re.split(punctuation_pattern, text)\n",
        "        sub_sentences = [p for p in parts if p.strip()]\n",
        "        if not sub_sentences:\n",
        "            final_segments.append(segment)\n",
        "            continue\n",
        "        current_sentence = \"\"\n",
        "        total_len = sum(len(s) for s in sub_sentences)\n",
        "        if total_len <= 0: total_len = 1\n",
        "        current_start = start_time\n",
        "        for sub in sub_sentences:\n",
        "            if len(current_sentence) > 0 and len(current_sentence + sub) > max_chars:\n",
        "                ratio = len(current_sentence) / total_len\n",
        "                new_end = current_start + (ratio * duration)\n",
        "                final_segments.append({'start': current_start, 'end': new_end, 'text': current_sentence})\n",
        "                current_start = new_end\n",
        "                current_sentence = sub\n",
        "            else:\n",
        "                current_sentence += (\" \" if current_sentence and not re.match(r'^[ï¼Œã€‚ã€ï¼Ÿï¼]', sub) else \"\") + sub\n",
        "        if current_sentence:\n",
        "            final_segments.append({'start': current_start, 'end': end_time, 'text': current_sentence})\n",
        "\n",
        "    deduped = []\n",
        "    for s in final_segments:\n",
        "        if not deduped or s['text'] != deduped[-1]['text']:\n",
        "            deduped.append(s)\n",
        "        else:\n",
        "            deduped[-1]['end'] = s['end']\n",
        "    for i, seg in enumerate(deduped): seg['id'] = i\n",
        "    return deduped\n",
        "\n",
        "def generate_srt_from_segments(segments):\n",
        "    srt_content = []\n",
        "    for i, segment in enumerate(segments):\n",
        "        start_time, end_time = format_srt_time(segment['start']), format_srt_time(segment['end'])\n",
        "        text = segment['text'].strip()\n",
        "        if text:\n",
        "            srt_content.append(str(i + 1))\n",
        "            srt_content.append(f\"{start_time} --> {end_time}\")\n",
        "            srt_content.append(text)\n",
        "            srt_content.append(\"\")\n",
        "    return \"\\n\".join(srt_content)\n",
        "\n",
        "def fix_and_process_srt(srt_content, remove_punctuation=True):\n",
        "    try:\n",
        "        cleaned_content = \"\\n\".join(line for line in srt_content.strip().splitlines() if line.strip())\n",
        "        subs = list(srt.parse(cleaned_content))\n",
        "        for sub in subs:\n",
        "            mod = sub.content.strip()\n",
        "            if remove_punctuation: mod = mod.rstrip('.,ã€‚?!ï¼?ï¼Ÿ')\n",
        "            sub.content = mod.strip()\n",
        "        return srt.compose(subs)\n",
        "    except: return srt_content\n",
        "\n",
        "# --- 2. å¼•æ“æ¨¡çµ„ ---\n",
        "class WhisperEngineCloud:\n",
        "    def __init__(self):\n",
        "        self.model = None\n",
        "        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "        self.model_size = None\n",
        "\n",
        "    def load_model(self, model_size=\"large\"):\n",
        "        if self.model is not None and self.model_size == model_size: return\n",
        "        self.model = whisper.load_model(model_size, device=self.device)\n",
        "        self.model_size = model_size\n",
        "\n",
        "    def transcribe(self, audio_path, prompt=\"\"):\n",
        "        return self.model.transcribe(audio_path, initial_prompt=prompt, verbose=True)\n",
        "\n",
        "# å»ºç«‹å…¨åŸŸå¯¦ä¾‹ (UI æœƒå‘¼å«å®ƒ)\n",
        "engine = WhisperEngineCloud()\n",
        "print(\"âœ… [Cell 2] æ ¸å¿ƒé‚è¼¯è¼‰å…¥å®Œç•¢\")\n"
      ],
      "metadata": {
        "id": "hKnBIT1i6LES"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import gc\n",
        "import torch\n",
        "import os\n",
        "import yt_dlp\n",
        "import traceback\n",
        "\n",
        "# --- æ ¸å¿ƒæ‰¹æ¬¡è™•ç†é‚è¼¯ ---\n",
        "def batch_process_transcription(files, yt_input, input_type, model_size, remove_punc, progress=gr.Progress()):\n",
        "    if 'engine' not in globals():\n",
        "        yield \"âŒ éŒ¯èª¤ï¼šè«‹å…ˆåŸ·è¡Œ Cell 2ï¼\", []\n",
        "        return\n",
        "\n",
        "    try:\n",
        "        log_content = \"ğŸš€ å•Ÿå‹•æ‰¹æ¬¡è½‰éŒ„ä»»å‹™...\\n\"\n",
        "        output_files = []\n",
        "\n",
        "        # æ±ºå®šè™•ç†åˆ—è¡¨\n",
        "        if input_type == \"YouTube é€£çµ\":\n",
        "            if not yt_input:\n",
        "                yield \"âŒ éŒ¯èª¤ï¼šè«‹è²¼ä¸Šç¶²å€\", []\n",
        "                return\n",
        "            target_files = [(\"YouTube\", yt_input)]\n",
        "        else:\n",
        "            if not files:\n",
        "                yield \"âŒ éŒ¯èª¤ï¼šè«‹å…ˆä¸Šå‚³æª”æ¡ˆ\", []\n",
        "                return\n",
        "            target_files = [(\"Local\", f.name) for f in files]\n",
        "\n",
        "        for i, (f_type, f_path) in enumerate(target_files):\n",
        "            filename = os.path.basename(f_path) if f_type == \"Local\" else \"YouTube å½±ç‰‡\"\n",
        "            log_content += f\"æ­£åœ¨è™•ç† ({i+1}/{len(target_files)}): {filename}...\\n\"\n",
        "            yield log_content, output_files\n",
        "\n",
        "            # --- ä¸‹è¼‰/æº–å‚™éŸ³è¨Š ---\n",
        "            if f_type == \"YouTube\":\n",
        "                if os.path.exists('temp_audio.m4a'): os.remove('temp_audio.m4a')\n",
        "                ydl_opts = {'format': 'm4a/bestaudio/best', 'outtmpl': 'temp_audio.%(ext)s', 'quiet': True, 'user_agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36'}\n",
        "                with yt_dlp.YoutubeDL(ydl_opts) as ydl: ydl.download([f_path])\n",
        "                audio_source = 'temp_audio.m4a'\n",
        "            else:\n",
        "                audio_source = f_path\n",
        "\n",
        "            # --- AI è¾¨è­˜ ---\n",
        "            gc.collect()\n",
        "            if torch.cuda.is_available(): torch.cuda.empty_cache()\n",
        "\n",
        "            engine.load_model(model_size)\n",
        "            result = engine.transcribe(audio_source)\n",
        "\n",
        "            # --- æ ¼å¼å„ªåŒ– ---\n",
        "            refined = refine_srt_segments(result['segments'])\n",
        "            srt_content = generate_srt_from_segments(refined)\n",
        "            final_srt = fix_and_process_srt(srt_content, remove_punctuation=remove_punc)\n",
        "\n",
        "            # --- å­˜æª” ---\n",
        "            safe_name = \"\".join([c if c.isalnum() else \"_\" for c in filename])\n",
        "            out_path = os.path.abspath(f\"transcript_{safe_name}.srt\")\n",
        "            with open(out_path, \"w\", encoding=\"utf-8\") as f: f.write(final_srt)\n",
        "\n",
        "            output_files.append(out_path)\n",
        "            log_content += f\"âœ… {filename} è½‰éŒ„å®Œæˆï¼\\n\"\n",
        "            yield log_content, output_files\n",
        "\n",
        "        log_content += \"\\n--- ğŸ‰ å…¨éƒ¨æª”æ¡ˆè¾¨è­˜å®Œç•¢ ---\"\n",
        "        yield log_content, output_files\n",
        "\n",
        "    except Exception as e:\n",
        "        traceback.print_exc()\n",
        "        yield f\"âŒ è½‰éŒ„å¤±æ•—ï¼š{str(e)}\", output_files\n",
        "\n",
        "# --- UI ä½ˆç½® ---\n",
        "with gr.Blocks(title=\"Whisper Pro Batch\") as demo:\n",
        "    gr.Markdown(\"# ğŸš€ Whisper Pro å½±éŸ³æ‰¹æ¬¡è½‰éŒ„ä¸­å¿ƒ\")\n",
        "\n",
        "    with gr.Row():\n",
        "        with gr.Column(scale=1):\n",
        "            t_mode = gr.Radio([\"æª”æ¡ˆä¸Šå‚³ (æ”¯æ´å¤šé¸)\", \"YouTube é€£çµ\"], label=\"è¼¸å…¥æ¨¡å¼\", value=\"æª”æ¡ˆä¸Šå‚³ (æ”¯æ´å¤šé¸)\")\n",
        "            t_files = gr.File(label=\"ä¸Šå‚³å€\", file_count=\"multiple\", visible=True)\n",
        "            t_url = gr.Textbox(label=\"YouTube ç¶²å€\", visible=False)\n",
        "            t_model = gr.Dropdown([\"base\", \"medium\", \"large\"], label=\"ä½¿ç”¨æ¨¡å‹\", value=\"large\")\n",
        "            t_punc = gr.Checkbox(label=\"è‡ªå‹•ç§»é™¤å¥å°¾æ¨™é»\", value=True)\n",
        "            t_btn = gr.Button(\"ğŸ”¥ å•Ÿå‹•æ‰¹æ¬¡è¾¨è­˜\", variant=\"primary\")\n",
        "\n",
        "        with gr.Column(scale=2):\n",
        "            gr.Markdown(\"### ğŸ“‹ è™•ç†æ—¥èªŒèˆ‡æˆæœä¸‹è¼‰\")\n",
        "            t_log = gr.Textbox(label=\"å³æ™‚è™•ç†é€²åº¦\", lines=12, interactive=False)\n",
        "            t_out = gr.File(label=\"ğŸ“¥ è½‰éŒ„æˆæœä¸‹è¼‰ (SRT æª”æ¡ˆåˆ—è¡¨)\", file_count=\"multiple\")\n",
        "\n",
        "    t_mode.change(lambda x: (gr.update(visible=x==\"æª”æ¡ˆä¸Šå‚³ (æ”¯æ´å¤šé¸)\"), gr.update(visible=x==\"YouTube é€£çµ\")), t_mode, [t_files, t_url])\n",
        "    t_btn.click(batch_process_transcription, [t_files, t_url, t_mode, t_model, t_punc], [t_log, t_out])\n",
        "\n",
        "demo.queue().launch(debug=True, share=True)\n"
      ],
      "metadata": {
        "id": "LxzQ9Qiv71V2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}