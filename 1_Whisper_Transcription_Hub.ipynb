{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOpJ1eIFHKghRTt9ciontNu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jack978397/Colab-AI-Transcribe-Translate/blob/main/1_Whisper_Transcription_Hub.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pMypEvui4pET"
      },
      "outputs": [],
      "source": [
        "# --- Cell 1: ç’°å¢ƒå®‰è£ ---\n",
        "!pip install openai-whisper yt-dlp srt \"moviepy<2.0.0\" Gradio google-generativeai\n",
        "!apt-get install -y ffmpeg\n",
        "print(\"\\n--- âœ… API èˆ‡å½±éŸ³ç’°å¢ƒå®‰è£å®Œæˆï¼ ---\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import whisper, torch, os, re, datetime, srt, yt_dlp, gc\n",
        "\n",
        "# --- 1. æ ¸å¿ƒå·¥å…·å‡½å¼ (é‚„åŸæ‚¨çš„åŸå§‹æ ¡æ­£é‚è¼¯) ---\n",
        "def format_srt_time(seconds):\n",
        "    delta = datetime.timedelta(seconds=max(0, seconds))\n",
        "    hours, remainder = divmod(delta.seconds, 3600)\n",
        "    minutes, seconds = divmod(remainder, 60)\n",
        "    milliseconds = delta.microseconds // 1000\n",
        "    return f\"{hours:02}:{minutes:02}:{seconds:02},{milliseconds:03}\"\n",
        "\n",
        "def refine_srt_segments(segments, max_chars=18):\n",
        "    if not segments: return []\n",
        "    pre_filtered = []\n",
        "    last_text = None\n",
        "    for seg in segments:\n",
        "        text = seg['text'].strip()\n",
        "        if not text: continue\n",
        "        if text == last_text and (seg['end'] - seg['start']) < 0.8:\n",
        "            if pre_filtered: pre_filtered[-1]['end'] = seg['end']\n",
        "            continue\n",
        "        pre_filtered.append(seg)\n",
        "        last_text = text\n",
        "\n",
        "    final_segments = []\n",
        "    punctuation_pattern = r'([ï¼Œã€‚ã€ï¼Ÿï¼,.\\\\!\\\\?])'\n",
        "    for segment in pre_filtered:\n",
        "        text = segment['text'].strip()\n",
        "        if not text or len(text) <= max_chars:\n",
        "            final_segments.append(segment)\n",
        "            continue\n",
        "        start_time, end_time = segment['start'], segment['end']\n",
        "        duration = end_time - start_time\n",
        "        parts = re.split(punctuation_pattern, text)\n",
        "        sub_sentences = [p for p in parts if p.strip()]\n",
        "        if not sub_sentences:\n",
        "            final_segments.append(segment)\n",
        "            continue\n",
        "        current_sentence = \"\"\n",
        "        total_len = sum(len(s) for s in sub_sentences)\n",
        "        if total_len <= 0: total_len = 1\n",
        "        current_start = start_time\n",
        "        for sub in sub_sentences:\n",
        "            if len(current_sentence) > 0 and len(current_sentence + sub) > max_chars:\n",
        "                ratio = len(current_sentence) / total_len\n",
        "                new_end = current_start + (ratio * duration)\n",
        "                final_segments.append({'start': current_start, 'end': new_end, 'text': current_sentence})\n",
        "                current_start = new_end\n",
        "                current_sentence = sub\n",
        "            else:\n",
        "                current_sentence += (\" \" if current_sentence and not re.match(r'^[ï¼Œã€‚ã€ï¼Ÿï¼]', sub) else \"\") + sub\n",
        "        if current_sentence:\n",
        "            final_segments.append({'start': current_start, 'end': end_time, 'text': current_sentence})\n",
        "\n",
        "    deduped = []\n",
        "    for s in final_segments:\n",
        "        if not deduped or s['text'] != deduped[-1]['text']:\n",
        "            deduped.append(s)\n",
        "        else:\n",
        "            deduped[-1]['end'] = s['end']\n",
        "    for i, seg in enumerate(deduped): seg['id'] = i\n",
        "    return deduped\n",
        "\n",
        "def generate_srt_from_segments(segments):\n",
        "    srt_content = []\n",
        "    for i, segment in enumerate(segments):\n",
        "        start_time, end_time = format_srt_time(segment['start']), format_srt_time(segment['end'])\n",
        "        text = segment['text'].strip()\n",
        "        if text:\n",
        "            srt_content.append(str(i + 1))\n",
        "            srt_content.append(f\"{start_time} --> {end_time}\")\n",
        "            srt_content.append(text)\n",
        "            srt_content.append(\"\")\n",
        "    return \"\\n\".join(srt_content)\n",
        "\n",
        "def fix_and_process_srt(srt_content, remove_punctuation=True):\n",
        "    try:\n",
        "        cleaned_content = \"\\n\".join(line for line in srt_content.strip().splitlines() if line.strip())\n",
        "        subs = list(srt.parse(cleaned_content))\n",
        "        for sub in subs:\n",
        "            mod = sub.content.strip()\n",
        "            if remove_punctuation: mod = mod.rstrip('.,ã€‚?!ï¼?ï¼Ÿ')\n",
        "            sub.content = mod.strip()\n",
        "        return srt.compose(subs)\n",
        "    except: return srt_content\n",
        "\n",
        "# --- 2. å¼•æ“æ¨¡çµ„ ---\n",
        "class WhisperEngineCloud:\n",
        "    def __init__(self):\n",
        "        self.model = None\n",
        "        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "        self.model_size = None\n",
        "\n",
        "    def load_model(self, model_size=\"large\"):\n",
        "        if self.model is not None and self.model_size == model_size: return\n",
        "        self.model = whisper.load_model(model_size, device=self.device)\n",
        "        self.model_size = model_size\n",
        "\n",
        "    def transcribe(self, audio_path, prompt=\"\"):\n",
        "        return self.model.transcribe(audio_path, initial_prompt=prompt, verbose=True)\n",
        "\n",
        "engine = WhisperEngineCloud()\n",
        "print(\"âœ… [Cell 2] æ ¸å¿ƒé‚è¼¯è¼‰å…¥å®Œç•¢\")\n"
      ],
      "metadata": {
        "id": "hKnBIT1i6LES"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr, gc, torch, os, yt_dlp, traceback, sys, io, glob\n",
        "\n",
        "# --- æ ¸å¿ƒï¼šäº’å‹•å¼å–ä»£ (åŒæ™‚ä¿®æ­£ Log æ–‡å­—èˆ‡ç£ç¢Ÿä¸Šçš„æª”æ¡ˆ) ---\n",
        "def interactive_fix(current_log, old_items, new_items):\n",
        "    if not old_items.strip(): return current_log, gr.update()\n",
        "\n",
        "    olds = old_items.strip().split('\\n')\n",
        "    news = new_items.strip().split('\\n')\n",
        "\n",
        "    # 1. ä¿®æ­£ä»‹é¢ä¸Šçš„æ—¥èªŒæ–‡å­—\n",
        "    updated_log = current_log\n",
        "    for o, n in zip(olds, news):\n",
        "        o_c, n_c = o.strip(), (n.strip() if n else \"\")\n",
        "        if o_c: updated_log = updated_log.replace(o_c, n_c)\n",
        "\n",
        "    # 2. åŒæ­¥ä¿®æ­£ç£ç¢Ÿä¸Šçš„æ‰€æœ‰ SRT æª”æ¡ˆï¼Œç¢ºä¿ä¸‹è¼‰çš„æ˜¯æ­£ç¢ºçš„\n",
        "    srt_files = glob.glob(\"*.srt\")\n",
        "    for srt_path in srt_files:\n",
        "        with open(srt_path, \"r\", encoding=\"utf-8\") as f:\n",
        "            content = f.read()\n",
        "\n",
        "        new_content = content\n",
        "        for o, n in zip(olds, news):\n",
        "            o_c, n_c = o.strip(), (n.strip() if n else \"\")\n",
        "            if o_c: new_content = new_content.replace(o_c, n_c)\n",
        "\n",
        "        with open(srt_path, \"w\", encoding=\"utf-8\") as f:\n",
        "            f.write(new_content)\n",
        "\n",
        "    return updated_log, srt_files # å›å‚³æ›´æ–°å¾Œçš„æ–‡å­—èˆ‡æª”æ¡ˆåˆ—è¡¨\n",
        "\n",
        "def batch_process_transcription(files, yt_input, input_type, model_size, remove_punc, max_ch, old_txt, new_txt, download_v, progress=gr.Progress()):\n",
        "    if 'engine' not in globals():\n",
        "        yield \"âŒ éŒ¯èª¤ï¼šè«‹å…ˆåŸ·è¡Œ Cell 2ï¼\", []\n",
        "        return\n",
        "    output_buffer = io.StringIO(); sys.stdout = output_buffer\n",
        "    log_content = \"ğŸš€ å•Ÿå‹•æ‰¹æ¬¡ä»»å‹™...\\n\"\n",
        "\n",
        "    try:\n",
        "        output_files = []\n",
        "        target_files = [(\"YouTube\", yt_input)] if input_type == \"YouTube é€£çµ\" else [(\"Local\", f.name) for f in files]\n",
        "\n",
        "        for i, (f_type, f_path) in enumerate(target_files):\n",
        "            filename = os.path.basename(f_path) if f_type == \"Local\" else \"YouTube å½±ç‰‡\"\n",
        "            log_content += f\"æ­£åœ¨è™•ç† ({i+1}/{len(target_files)}): {filename}...\\n\"; yield log_content, output_files\n",
        "\n",
        "            # --- ä¸‹è¼‰/æº–å‚™ ---\n",
        "            temp_audio = 'cloud_temp_audio.mp3'\n",
        "            if f_type == \"YouTube\":\n",
        "                if download_v:\n",
        "                    ydl_opts = {'format': 'mp4', 'outtmpl': 'yt_video_%(title)s.%(ext)s', 'quiet': True}\n",
        "                    with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
        "                        info = ydl.extract_info(f_path, download=True); v_path = ydl.prepare_filename(info); filename = info.get('title', 'YouTubeå½±ç‰‡')\n",
        "                    os.system(f'ffmpeg -i \"{v_path}\" -q:a 0 -map a \"{temp_audio}\" -y -loglevel error')\n",
        "                    output_files.append(v_path)\n",
        "                else:\n",
        "                    ydl_opts = {'format': 'bestaudio', 'outtmpl': 'tmp.m4a', 'quiet': True}\n",
        "                    with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
        "                        info = ydl.extract_info(f_path, download=True); d_file = ydl.prepare_filename(info); filename = info.get('title', 'YouTubeå½±ç‰‡')\n",
        "                    os.system(f'ffmpeg -i \"{d_file}\" \"{temp_audio}\" -y -loglevel error')\n",
        "                audio_source = temp_audio\n",
        "            else:\n",
        "                os.system(f'ffmpeg -i \"{f_path}\" \"{temp_audio}\" -y -loglevel error'); audio_source = temp_audio\n",
        "\n",
        "            # --- è½‰éŒ„ ---\n",
        "            gc.collect(); torch.cuda.empty_cache() if torch.cuda.is_available() else None\n",
        "            engine.load_model(model_size); result = engine.transcribe(audio_source)\n",
        "            log_content += output_buffer.getvalue(); output_buffer.truncate(0); output_buffer.seek(0)\n",
        "\n",
        "            # --- æ ¡æ­£èˆ‡åˆæ­¥å–ä»£ ---\n",
        "            refined = refine_srt_segments(result['segments'], max_chars=max_ch)\n",
        "            final_srt = generate_srt_from_segments(refined)\n",
        "            final_srt = fix_and_process_srt(final_srt, remove_punctuation=remove_punc)\n",
        "\n",
        "            # é€™è£¡ä¹Ÿæœƒè·‘ä¸€æ¬¡é è¨­å–ä»£\n",
        "            olds, news = old_txt.strip().split('\\n'), new_txt.strip().split('\\n')\n",
        "            for o, n in zip(olds, news):\n",
        "                if o.strip(): final_srt = final_srt.replace(o.strip(), n.strip() if n else \"\")\n",
        "\n",
        "            # --- å­˜æª” ---\n",
        "            safe_name = \"\".join([c if c.isalnum() else \"_\" for c in filename[:15]])\n",
        "            out_path = os.path.abspath(f\"transcript_{safe_name}.srt\")\n",
        "            with open(out_path, \"w\", encoding=\"utf-8\") as f: f.write(final_srt)\n",
        "            output_files.append(out_path)\n",
        "            log_content += f\"âœ… {filename} å®Œæˆï¼\\n\"; yield log_content, output_files\n",
        "\n",
        "        log_content += \"\\n--- ğŸ‰ å…¨éƒ¨æª”æ¡ˆè¾¨è­˜å®Œç•¢ ---\"; yield log_content, output_files\n",
        "    except Exception as e: yield log_content + f\"\\nâŒ éŒ¯èª¤: {e}\", output_files\n",
        "    finally: sys.stdout = sys.__stdout__\n",
        "\n",
        "# --- UI ä½ˆç½® ---\n",
        "with gr.Blocks(theme=gr.themes.Soft()) as demo:\n",
        "    gr.Markdown(\"# ğŸš€ Whisper Pro å½±éŸ³æ‰¹æ¬¡è½‰éŒ„ä¸­å¿ƒ\")\n",
        "    with gr.Row():\n",
        "        with gr.Column(scale=1):\n",
        "            t_mode = gr.Radio([\"æª”æ¡ˆä¸Šå‚³ (æ”¯æ´å¤šé¸)\", \"YouTube é€£çµ\"], label=\"è¼¸å…¥æ¨¡å¼\", value=\"æª”æ¡ˆä¸Šå‚³ (æ”¯æ´å¤šé¸)\")\n",
        "            t_files = gr.File(label=\"ä¸Šå‚³å€\", file_count=\"multiple\", visible=True)\n",
        "            t_url = gr.Textbox(label=\"YouTube ç¶²å€\", visible=False)\n",
        "            t_model = gr.Dropdown([\"base\", \"medium\", \"large\"], label=\"ä½¿ç”¨æ¨¡å‹\", value=\"large\")\n",
        "            t_punc = gr.Checkbox(label=\"è‡ªå‹•ç§»é™¤å¥å°¾æ¨™é»\", value=True)\n",
        "\n",
        "            with gr.Accordion(\"âš™ï¸ é€²éšæ ¼å¼èˆ‡å–ä»£è¨­å®š\", open=True):\n",
        "                t_max_ch = gr.Slider(10, 30, value=18, step=1, label=\"æ¯è¡Œæœ€å¤§å­—å…ƒ\")\n",
        "                t_dv = gr.Checkbox(label=\"åŒæ™‚ä¸‹è¼‰ YouTube å½±ç‰‡ (mp4)\", value=False)\n",
        "                with gr.Row():\n",
        "                    t_old = gr.Textbox(label=\"èˆŠè©æ¸…å–® (æ¯è¡Œä¸€å€‹)\", lines=3)\n",
        "                    t_new = gr.Textbox(label=\"æ–°è©æ¸…å–® (å°æ‡‰å·¦æ–¹)\", lines=3)\n",
        "                # âœ¨ æ–°å¢æŒ‰éˆ•ï¼šæ‰‹å‹•è£œå¼·å–ä»£\n",
        "                t_replace_btn = gr.Button(\"ğŸª„ ç«‹å³åŸ·è¡Œä¿®æ­£ (åŒæ™‚æ›´æ–°æ—¥èªŒèˆ‡æª”æ¡ˆ)\", variant=\"secondary\")\n",
        "\n",
        "            t_btn = gr.Button(\"ğŸ”¥ å•Ÿå‹•å®Œæ•´è¾¨è­˜ä»»å‹™\", variant=\"primary\")\n",
        "        with gr.Column(scale=2):\n",
        "            t_log = gr.Textbox(label=\"è™•ç†é€²åº¦èˆ‡æ—¥èªŒ (å¯æ‰‹å‹•ä¿®æ”¹å…§å®¹å¾ŒæŒ‰ä¸‹ä¿®æ­£æŒ‰éˆ•)\", lines=18)\n",
        "            t_out = gr.File(label=\"ğŸ“¥ è½‰éŒ„æˆæœä¸‹è¼‰ (SRT æª”æ¡ˆåˆ—è¡¨)\", file_count=\"multiple\")\n",
        "\n",
        "    t_mode.change(lambda x: (gr.update(visible=x==\"æª”æ¡ˆä¸Šå‚³ (æ”¯æ´å¤šé¸)\"), gr.update(visible=x==\"YouTube é€£çµ\")), t_mode, [t_files, t_url])\n",
        "\n",
        "    # äº‹ä»¶ï¼šå•Ÿå‹•è¾¨è­˜\n",
        "    t_btn.click(batch_process_transcription, [t_files, t_url, t_mode, t_model, t_punc, t_max_ch, t_old, t_new, t_dv], [t_log, t_out])\n",
        "\n",
        "    # âœ¨ äº‹ä»¶ï¼šæ‰‹å‹•å–ä»£ (é»äº†ä¹‹å¾Œï¼Œæ—¥èªŒæœƒè®Šã€ç£ç¢Ÿè£¡çš„æª”æ¡ˆä¹Ÿæœƒæ›´æ–°ï¼Œä¸‹è¼‰é€£çµæœƒåŒæ­¥è®Šå‹•)\n",
        "    t_replace_btn.click(interactive_fix, inputs=[t_log, t_old, t_new], outputs=[t_log, t_out])\n",
        "\n",
        "demo.queue().launch(share=True, debug=True)\n"
      ],
      "metadata": {
        "id": "LxzQ9Qiv71V2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}