{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOpJ1eIFHKghRTt9ciontNu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jack978397/Colab-AI-Transcribe-Translate/blob/main/1_Whisper_Transcription_Hub.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "pMypEvui4pET",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "25c3a96d-ef44-4417-9f86-f2e9b6cfdc04"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai-whisper in /usr/local/lib/python3.12/dist-packages (20250625)\n",
            "Requirement already satisfied: yt-dlp in /usr/local/lib/python3.12/dist-packages (2026.2.21)\n",
            "Requirement already satisfied: srt in /usr/local/lib/python3.12/dist-packages (3.5.3)\n",
            "Requirement already satisfied: moviepy<2.0.0 in /usr/local/lib/python3.12/dist-packages (1.0.3)\n",
            "Requirement already satisfied: Gradio in /usr/local/lib/python3.12/dist-packages (5.50.0)\n",
            "Requirement already satisfied: google-generativeai in /usr/local/lib/python3.12/dist-packages (0.8.6)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.12/dist-packages (from openai-whisper) (10.8.0)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.12/dist-packages (from openai-whisper) (0.60.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from openai-whisper) (2.0.2)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.12/dist-packages (from openai-whisper) (0.12.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from openai-whisper) (2.10.0+cu128)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from openai-whisper) (4.67.3)\n",
            "Requirement already satisfied: triton>=2 in /usr/local/lib/python3.12/dist-packages (from openai-whisper) (3.6.0)\n",
            "Requirement already satisfied: decorator<5.0,>=4.0.2 in /usr/local/lib/python3.12/dist-packages (from moviepy<2.0.0) (4.4.2)\n",
            "Requirement already satisfied: requests<3.0,>=2.8.1 in /usr/local/lib/python3.12/dist-packages (from moviepy<2.0.0) (2.32.4)\n",
            "Requirement already satisfied: proglog<=1.0.0 in /usr/local/lib/python3.12/dist-packages (from moviepy<2.0.0) (0.1.12)\n",
            "Requirement already satisfied: imageio<3.0,>=2.5 in /usr/local/lib/python3.12/dist-packages (from moviepy<2.0.0) (2.37.2)\n",
            "Requirement already satisfied: imageio-ffmpeg>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from moviepy<2.0.0) (0.6.0)\n",
            "Requirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.12/dist-packages (from Gradio) (24.1.0)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.12/dist-packages (from Gradio) (4.12.1)\n",
            "Requirement already satisfied: brotli>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from Gradio) (1.2.0)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.12/dist-packages (from Gradio) (0.129.0)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.12/dist-packages (from Gradio) (1.0.0)\n",
            "Requirement already satisfied: gradio-client==1.14.0 in /usr/local/lib/python3.12/dist-packages (from Gradio) (1.14.0)\n",
            "Requirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.12/dist-packages (from Gradio) (0.1.2)\n",
            "Requirement already satisfied: httpx<1.0,>=0.24.1 in /usr/local/lib/python3.12/dist-packages (from Gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub<2.0,>=0.33.5 in /usr/local/lib/python3.12/dist-packages (from Gradio) (1.4.1)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.12/dist-packages (from Gradio) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.12/dist-packages (from Gradio) (3.0.3)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.12/dist-packages (from Gradio) (3.11.7)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from Gradio) (26.0)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.12/dist-packages (from Gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.12/dist-packages (from Gradio) (11.3.0)\n",
            "Requirement already satisfied: pydantic<=2.12.3,>=2.0 in /usr/local/lib/python3.12/dist-packages (from Gradio) (2.12.3)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.12/dist-packages (from Gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.12/dist-packages (from Gradio) (0.0.22)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.12/dist-packages (from Gradio) (6.0.3)\n",
            "Requirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.12/dist-packages (from Gradio) (0.15.1)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.12/dist-packages (from Gradio) (0.1.7)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.12/dist-packages (from Gradio) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.12/dist-packages (from Gradio) (0.52.1)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from Gradio) (0.13.3)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.12/dist-packages (from Gradio) (0.24.0)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.12/dist-packages (from Gradio) (4.15.0)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.12/dist-packages (from Gradio) (0.41.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from gradio-client==1.14.0->Gradio) (2025.3.0)\n",
            "Requirement already satisfied: websockets<16.0,>=13.0 in /usr/local/lib/python3.12/dist-packages (from gradio-client==1.14.0->Gradio) (15.0.1)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (0.6.15)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (2.29.0)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (2.190.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (2.47.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (5.29.6)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.12/dist-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.27.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0,>=3.0->Gradio) (3.11)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from fastapi<1.0,>=0.115.2->Gradio) (0.4.2)\n",
            "Requirement already satisfied: annotated-doc>=0.0.2 in /usr/local/lib/python3.12/dist-packages (from fastapi<1.0,>=0.115.2->Gradio) (0.0.4)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core->google-generativeai) (1.72.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth>=2.15.0->google-generativeai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth>=2.15.0->google-generativeai) (4.9.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.24.1->Gradio) (2026.1.4)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.24.1->Gradio) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0,>=0.24.1->Gradio) (0.16.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.33.5->Gradio) (3.24.2)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.33.5->Gradio) (1.2.0)\n",
            "Requirement already satisfied: shellingham in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.33.5->Gradio) (1.5.4)\n",
            "Requirement already satisfied: typer-slim in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.33.5->Gradio) (0.24.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->Gradio) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->Gradio) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->Gradio) (2025.3)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<=2.12.3,>=2.0->Gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<=2.12.3,>=2.0->Gradio) (2.41.4)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0,>=2.8.1->moviepy<2.0.0) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0,>=2.8.1->moviepy<2.0.0) (2.5.0)\n",
            "Requirement already satisfied: click>=8.2.1 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->Gradio) (8.3.1)\n",
            "Requirement already satisfied: rich>=12.3.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->Gradio) (13.9.4)\n",
            "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client->google-generativeai) (0.31.2)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client->google-generativeai) (0.3.0)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client->google-generativeai) (4.2.0)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.12/dist-packages (from numba->openai-whisper) (0.43.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken->openai-whisper) (2025.11.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (3.6.1)\n",
            "Requirement already satisfied: cuda-bindings==12.9.4 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (12.9.4)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (12.8.93)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (12.8.90)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (12.8.90)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (12.8.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (11.3.3.83)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (10.3.9.90)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (11.7.3.90)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (12.5.8.93)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.4.5 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (3.4.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (12.8.90)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (12.8.93)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (1.13.1.3)\n",
            "Requirement already satisfied: cuda-pathfinder~=1.1 in /usr/local/lib/python3.12/dist-packages (from cuda-bindings==12.9.4->torch->openai-whisper) (1.3.4)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.78.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.71.2)\n",
            "Requirement already satisfied: pyparsing<4,>=3.1 in /usr/local/lib/python3.12/dist-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai) (3.3.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->Gradio) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=12.3.0->typer<1.0,>=0.12->Gradio) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=12.3.0->typer<1.0,>=0.12->Gradio) (2.19.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch->openai-whisper) (1.3.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=12.3.0->typer<1.0,>=0.12->Gradio) (0.1.2)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 37 not upgraded.\n",
            "\n",
            "--- âœ… API èˆ‡å½±éŸ³ç’°å¢ƒå®‰è£å®Œæˆï¼ ---\n"
          ]
        }
      ],
      "source": [
        "# --- Cell 1: ç’°å¢ƒå®‰è£ ---\n",
        "!pip install openai-whisper yt-dlp srt \"moviepy<2.0.0\" Gradio google-generativeai\n",
        "!apt-get install -y ffmpeg\n",
        "print(\"\\n--- âœ… API èˆ‡å½±éŸ³ç’°å¢ƒå®‰è£å®Œæˆï¼ ---\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import whisper, torch, os, re, datetime, srt, yt_dlp, gc\n",
        "\n",
        "# --- 1. æ ¸å¿ƒå·¥å…·å‡½å¼ (é‚„åŸæ‚¨çš„åŸå§‹æ ¡æ­£é‚è¼¯) ---\n",
        "def format_srt_time(seconds):\n",
        "    delta = datetime.timedelta(seconds=max(0, seconds))\n",
        "    hours, remainder = divmod(delta.seconds, 3600)\n",
        "    minutes, seconds = divmod(remainder, 60)\n",
        "    milliseconds = delta.microseconds // 1000\n",
        "    return f\"{hours:02}:{minutes:02}:{seconds:02},{milliseconds:03}\"\n",
        "\n",
        "def refine_srt_segments(segments, max_chars=18):\n",
        "    if not segments: return []\n",
        "    pre_filtered = []\n",
        "    last_text = None\n",
        "    for seg in segments:\n",
        "        text = seg['text'].strip()\n",
        "        if not text: continue\n",
        "        if text == last_text and (seg['end'] - seg['start']) < 0.8:\n",
        "            if pre_filtered: pre_filtered[-1]['end'] = seg['end']\n",
        "            continue\n",
        "        pre_filtered.append(seg)\n",
        "        last_text = text\n",
        "\n",
        "    final_segments = []\n",
        "    punctuation_pattern = r'([ï¼Œã€‚ã€ï¼Ÿï¼,.\\\\!\\\\?])'\n",
        "    for segment in pre_filtered:\n",
        "        text = segment['text'].strip()\n",
        "        if not text or len(text) <= max_chars:\n",
        "            final_segments.append(segment)\n",
        "            continue\n",
        "        start_time, end_time = segment['start'], segment['end']\n",
        "        duration = end_time - start_time\n",
        "        parts = re.split(punctuation_pattern, text)\n",
        "        sub_sentences = [p for p in parts if p.strip()]\n",
        "        if not sub_sentences:\n",
        "            final_segments.append(segment)\n",
        "            continue\n",
        "        current_sentence = \"\"\n",
        "        total_len = sum(len(s) for s in sub_sentences)\n",
        "        if total_len <= 0: total_len = 1\n",
        "        current_start = start_time\n",
        "        for sub in sub_sentences:\n",
        "            if len(current_sentence) > 0 and len(current_sentence + sub) > max_chars:\n",
        "                ratio = len(current_sentence) / total_len\n",
        "                new_end = current_start + (ratio * duration)\n",
        "                final_segments.append({'start': current_start, 'end': new_end, 'text': current_sentence})\n",
        "                current_start = new_end\n",
        "                current_sentence = sub\n",
        "            else:\n",
        "                current_sentence += (\" \" if current_sentence and not re.match(r'^[ï¼Œã€‚ã€ï¼Ÿï¼]', sub) else \"\") + sub\n",
        "        if current_sentence:\n",
        "            final_segments.append({'start': current_start, 'end': end_time, 'text': current_sentence})\n",
        "\n",
        "    deduped = []\n",
        "    for s in final_segments:\n",
        "        if not deduped or s['text'] != deduped[-1]['text']:\n",
        "            deduped.append(s)\n",
        "        else:\n",
        "            deduped[-1]['end'] = s['end']\n",
        "    for i, seg in enumerate(deduped): seg['id'] = i\n",
        "    return deduped\n",
        "\n",
        "def generate_srt_from_segments(segments):\n",
        "    srt_content = []\n",
        "    for i, segment in enumerate(segments):\n",
        "        start_time, end_time = format_srt_time(segment['start']), format_srt_time(segment['end'])\n",
        "        text = segment['text'].strip()\n",
        "        if text:\n",
        "            srt_content.append(str(i + 1))\n",
        "            srt_content.append(f\"{start_time} --> {end_time}\")\n",
        "            srt_content.append(text)\n",
        "            srt_content.append(\"\")\n",
        "    return \"\\n\".join(srt_content)\n",
        "\n",
        "def fix_and_process_srt(srt_content, remove_punctuation=True):\n",
        "    try:\n",
        "        cleaned_content = \"\\n\".join(line for line in srt_content.strip().splitlines() if line.strip())\n",
        "        subs = list(srt.parse(cleaned_content))\n",
        "        for sub in subs:\n",
        "            mod = sub.content.strip()\n",
        "            if remove_punctuation: mod = mod.rstrip('.,ã€‚?!ï¼?ï¼Ÿ')\n",
        "            sub.content = mod.strip()\n",
        "        return srt.compose(subs)\n",
        "    except: return srt_content\n",
        "\n",
        "# --- 2. å¼•æ“æ¨¡çµ„ ---\n",
        "class WhisperEngineCloud:\n",
        "    def __init__(self):\n",
        "        self.model = None\n",
        "        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "        self.model_size = None\n",
        "\n",
        "    def load_model(self, model_size=\"large\"):\n",
        "        if self.model is not None and self.model_size == model_size: return\n",
        "        self.model = whisper.load_model(model_size, device=self.device)\n",
        "        self.model_size = model_size\n",
        "\n",
        "    def transcribe(self, audio_path, prompt=\"\"):\n",
        "        return self.model.transcribe(audio_path, initial_prompt=prompt, verbose=True)\n",
        "\n",
        "engine = WhisperEngineCloud()\n",
        "print(\"âœ… [Cell 2] æ ¸å¿ƒé‚è¼¯è¼‰å…¥å®Œç•¢\")\n"
      ],
      "metadata": {
        "id": "hKnBIT1i6LES",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "516381d4-a197-46c3-dce0-5c0e2bd7d408"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… [Cell 2] æ ¸å¿ƒé‚è¼¯è¼‰å…¥å®Œç•¢\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr, gc, torch, os, yt_dlp, traceback, sys, io, glob\n",
        "\n",
        "# --- æ ¸å¿ƒï¼šäº’å‹•å¼å–ä»£ (åŒæ™‚ä¿®æ­£ Log æ–‡å­—èˆ‡ç£ç¢Ÿä¸Šçš„æª”æ¡ˆ) ---\n",
        "def interactive_fix(current_log, old_items, new_items):\n",
        "    if not old_items.strip(): return current_log, gr.update()\n",
        "\n",
        "    olds = old_items.strip().split('\\n')\n",
        "    news = new_items.strip().split('\\n')\n",
        "\n",
        "    # 1. ä¿®æ­£ä»‹é¢ä¸Šçš„æ—¥èªŒæ–‡å­—\n",
        "    updated_log = current_log\n",
        "    for o, n in zip(olds, news):\n",
        "        o_c, n_c = o.strip(), (n.strip() if n else \"\")\n",
        "        if o_c: updated_log = updated_log.replace(o_c, n_c)\n",
        "\n",
        "    # 2. åŒæ­¥ä¿®æ­£ç£ç¢Ÿä¸Šçš„æ‰€æœ‰ SRT æª”æ¡ˆï¼Œç¢ºä¿ä¸‹è¼‰çš„æ˜¯æ­£ç¢ºçš„\n",
        "    srt_files = glob.glob(\"*.srt\")\n",
        "    for srt_path in srt_files:\n",
        "        with open(srt_path, \"r\", encoding=\"utf-8\") as f:\n",
        "            content = f.read()\n",
        "\n",
        "        new_content = content\n",
        "        for o, n in zip(olds, news):\n",
        "            o_c, n_c = o.strip(), (n.strip() if n else \"\")\n",
        "            if o_c: new_content = new_content.replace(o_c, n_c)\n",
        "\n",
        "        with open(srt_path, \"w\", encoding=\"utf-8\") as f:\n",
        "            f.write(new_content)\n",
        "\n",
        "    return updated_log, srt_files # å›å‚³æ›´æ–°å¾Œçš„æ–‡å­—èˆ‡æª”æ¡ˆåˆ—è¡¨\n",
        "\n",
        "def batch_process_transcription(files, yt_input, input_type, model_size, remove_punc, max_ch, old_txt, new_txt, download_v, progress=gr.Progress()):\n",
        "    if 'engine' not in globals():\n",
        "        yield \"âŒ éŒ¯èª¤ï¼šè«‹å…ˆåŸ·è¡Œ Cell 2ï¼\", []\n",
        "        return\n",
        "    output_buffer = io.StringIO(); sys.stdout = output_buffer\n",
        "    log_content = \"ğŸš€ å•Ÿå‹•æ‰¹æ¬¡ä»»å‹™...\\n\"\n",
        "\n",
        "    try:\n",
        "        output_files = []\n",
        "        target_files = [(\"YouTube\", yt_input)] if input_type == \"YouTube é€£çµ\" else [(\"Local\", f.name) for f in files]\n",
        "\n",
        "        for i, (f_type, f_path) in enumerate(target_files):\n",
        "            filename = os.path.basename(f_path) if f_type == \"Local\" else \"YouTube å½±ç‰‡\"\n",
        "            log_content += f\"æ­£åœ¨è™•ç† ({i+1}/{len(target_files)}): {filename}...\\n\"; yield log_content, output_files\n",
        "\n",
        "            # --- ä¸‹è¼‰/æº–å‚™ ---\n",
        "            temp_audio = 'cloud_temp_audio.mp3'\n",
        "            if f_type == \"YouTube\":\n",
        "                if download_v:\n",
        "                    ydl_opts = {'format': 'mp4', 'outtmpl': 'yt_video_%(title)s.%(ext)s', 'quiet': True}\n",
        "                    with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
        "                        info = ydl.extract_info(f_path, download=True); v_path = ydl.prepare_filename(info); filename = info.get('title', 'YouTubeå½±ç‰‡')\n",
        "                    os.system(f'ffmpeg -i \"{v_path}\" -q:a 0 -map a \"{temp_audio}\" -y -loglevel error')\n",
        "                    output_files.append(v_path)\n",
        "                else:\n",
        "                    ydl_opts = {'format': 'bestaudio', 'outtmpl': 'tmp.m4a', 'quiet': True}\n",
        "                    with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
        "                        info = ydl.extract_info(f_path, download=True); d_file = ydl.prepare_filename(info); filename = info.get('title', 'YouTubeå½±ç‰‡')\n",
        "                    os.system(f'ffmpeg -i \"{d_file}\" \"{temp_audio}\" -y -loglevel error')\n",
        "                audio_source = temp_audio\n",
        "            else:\n",
        "                os.system(f'ffmpeg -i \"{f_path}\" \"{temp_audio}\" -y -loglevel error'); audio_source = temp_audio\n",
        "\n",
        "            # --- è½‰éŒ„ ---\n",
        "            gc.collect(); torch.cuda.empty_cache() if torch.cuda.is_available() else None\n",
        "            engine.load_model(model_size); result = engine.transcribe(audio_source)\n",
        "            log_content += output_buffer.getvalue(); output_buffer.truncate(0); output_buffer.seek(0)\n",
        "\n",
        "            # --- æ ¡æ­£èˆ‡åˆæ­¥å–ä»£ ---\n",
        "            refined = refine_srt_segments(result['segments'], max_chars=max_ch)\n",
        "            final_srt = generate_srt_from_segments(refined)\n",
        "            final_srt = fix_and_process_srt(final_srt, remove_punctuation=remove_punc)\n",
        "\n",
        "            # é€™è£¡ä¹Ÿæœƒè·‘ä¸€æ¬¡é è¨­å–ä»£\n",
        "            olds, news = old_txt.strip().split('\\n'), new_txt.strip().split('\\n')\n",
        "            for o, n in zip(olds, news):\n",
        "                if o.strip(): final_srt = final_srt.replace(o.strip(), n.strip() if n else \"\")\n",
        "\n",
        "            # --- å­˜æª” ---\n",
        "            safe_name = \"\".join([c if c.isalnum() else \"_\" for c in filename[:15]])\n",
        "            out_path = os.path.abspath(f\"transcript_{safe_name}.srt\")\n",
        "            with open(out_path, \"w\", encoding=\"utf-8\") as f: f.write(final_srt)\n",
        "            output_files.append(out_path)\n",
        "            log_content += f\"âœ… {filename} å®Œæˆï¼\\n\"; yield log_content, output_files\n",
        "\n",
        "        log_content += \"\\n--- ğŸ‰ å…¨éƒ¨æª”æ¡ˆè¾¨è­˜å®Œç•¢ ---\"; yield log_content, output_files\n",
        "    except Exception as e: yield log_content + f\"\\nâŒ éŒ¯èª¤: {e}\", output_files\n",
        "    finally: sys.stdout = sys.__stdout__\n",
        "\n",
        "# --- UI ä½ˆç½® ---\n",
        "with gr.Blocks(theme=gr.themes.Soft()) as demo:\n",
        "    gr.Markdown(\"# ğŸš€ Whisper Pro å½±éŸ³æ‰¹æ¬¡è½‰éŒ„ä¸­å¿ƒ\")\n",
        "    with gr.Row():\n",
        "        with gr.Column(scale=1):\n",
        "            t_mode = gr.Radio([\"æª”æ¡ˆä¸Šå‚³ (æ”¯æ´å¤šé¸)\", \"YouTube é€£çµ\"], label=\"è¼¸å…¥æ¨¡å¼\", value=\"æª”æ¡ˆä¸Šå‚³ (æ”¯æ´å¤šé¸)\")\n",
        "            t_files = gr.File(label=\"ä¸Šå‚³å€\", file_count=\"multiple\", visible=True)\n",
        "            t_url = gr.Textbox(label=\"YouTube ç¶²å€\", visible=False)\n",
        "            t_model = gr.Dropdown([\"base\", \"medium\", \"large\"], label=\"ä½¿ç”¨æ¨¡å‹\", value=\"large\")\n",
        "            t_punc = gr.Checkbox(label=\"è‡ªå‹•ç§»é™¤å¥å°¾æ¨™é»\", value=True)\n",
        "\n",
        "            with gr.Accordion(\"âš™ï¸ é€²éšæ ¼å¼èˆ‡å–ä»£è¨­å®š\", open=True):\n",
        "                t_max_ch = gr.Slider(10, 30, value=18, step=1, label=\"æ¯è¡Œæœ€å¤§å­—å…ƒ\")\n",
        "                t_dv = gr.Checkbox(label=\"åŒæ™‚ä¸‹è¼‰ YouTube å½±ç‰‡ (mp4)\", value=False)\n",
        "                with gr.Row():\n",
        "                    t_old = gr.Textbox(label=\"èˆŠè©æ¸…å–® (æ¯è¡Œä¸€å€‹)\", lines=3)\n",
        "                    t_new = gr.Textbox(label=\"æ–°è©æ¸…å–® (å°æ‡‰å·¦æ–¹)\", lines=3)\n",
        "                # âœ¨ æ–°å¢æŒ‰éˆ•ï¼šæ‰‹å‹•è£œå¼·å–ä»£\n",
        "                t_replace_btn = gr.Button(\"ğŸª„ ç«‹å³åŸ·è¡Œä¿®æ­£ (åŒæ™‚æ›´æ–°æ—¥èªŒèˆ‡æª”æ¡ˆ)\", variant=\"secondary\")\n",
        "\n",
        "            t_btn = gr.Button(\"ğŸ”¥ å•Ÿå‹•å®Œæ•´è¾¨è­˜ä»»å‹™\", variant=\"primary\")\n",
        "        with gr.Column(scale=2):\n",
        "            t_log = gr.Textbox(label=\"è™•ç†é€²åº¦èˆ‡æ—¥èªŒ (å¯æ‰‹å‹•ä¿®æ”¹å…§å®¹å¾ŒæŒ‰ä¸‹ä¿®æ­£æŒ‰éˆ•)\", lines=18)\n",
        "            t_out = gr.File(label=\"ğŸ“¥ è½‰éŒ„æˆæœä¸‹è¼‰ (SRT æª”æ¡ˆåˆ—è¡¨)\", file_count=\"multiple\")\n",
        "\n",
        "    t_mode.change(lambda x: (gr.update(visible=x==\"æª”æ¡ˆä¸Šå‚³ (æ”¯æ´å¤šé¸)\"), gr.update(visible=x==\"YouTube é€£çµ\")), t_mode, [t_files, t_url])\n",
        "\n",
        "    # äº‹ä»¶ï¼šå•Ÿå‹•è¾¨è­˜\n",
        "    t_btn.click(batch_process_transcription, [t_files, t_url, t_mode, t_model, t_punc, t_max_ch, t_old, t_new, t_dv], [t_log, t_out])\n",
        "\n",
        "    # âœ¨ äº‹ä»¶ï¼šæ‰‹å‹•å–ä»£ (é»äº†ä¹‹å¾Œï¼Œæ—¥èªŒæœƒè®Šã€ç£ç¢Ÿè£¡çš„æª”æ¡ˆä¹Ÿæœƒæ›´æ–°ï¼Œä¸‹è¼‰é€£çµæœƒåŒæ­¥è®Šå‹•)\n",
        "    t_replace_btn.click(interactive_fix, inputs=[t_log, t_old, t_new], outputs=[t_log, t_out])\n",
        "\n",
        "demo.queue().launch(share=True, debug=True)\n"
      ],
      "metadata": {
        "id": "LxzQ9Qiv71V2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 669
        },
        "outputId": "1a091a9d-be17-42de-b211-4f46b2f7912a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1333738190.py:92: DeprecationWarning: The 'theme' parameter in the Blocks constructor will be removed in Gradio 6.0. You will need to pass 'theme' to Blocks.launch() instead.\n",
            "  with gr.Blocks(theme=gr.themes.Soft()) as demo:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://9ed98ecee7bf4310fe.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://9ed98ecee7bf4310fe.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING: [youtube] No supported JavaScript runtime could be found. Only deno is enabled by default; to use another runtime add  --js-runtimes RUNTIME[:PATH]  to your command/config. YouTube extraction without a JS runtime has been deprecated, and some formats may be missing. See  https://github.com/yt-dlp/yt-dlp/wiki/EJS  for details on installing one\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    }
  ]
}